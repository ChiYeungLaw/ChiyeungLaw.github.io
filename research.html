<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research - Ziyang's Page</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" type="image/jpeg" href="images/me.jpg">
    <script>
        // 立即设置主题，防止页面闪烁
        (function() {
            const savedTheme = localStorage.getItem('theme');
            const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
            const theme = savedTheme || (prefersDark ? 'dark' : 'light');
            document.documentElement.setAttribute('data-theme', theme);
        })();
    </script>
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-brand">Ziyang's Page</div>
            <div class="nav-links">
                <a href="index.html" class="nav-link">Home</a>
                <a href="research.html" class="nav-link active">Research</a>
                <a href="contact.html" class="nav-link">Contact</a>
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M12 18a6 6 0 1 1 0-12 6 6 0 0 1 0 12zm0-2a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM11 1h2v3h-2V1zm0 19h2v3h-2v-3zM3.515 4.929l1.414-1.414L7.05 5.636 5.636 7.05 3.515 4.93zM16.95 18.364l1.414-1.414 2.121 2.121-1.414 1.414-2.121-2.121zm2.121-14.85l1.414 1.415-2.121 2.121-1.414-1.414 2.121-2.121zM5.636 16.95l1.414 1.414-2.121 2.121-1.414-1.414 2.121-2.121zM23 11v2h-3v-2h3zM4 11v2H1v-2h3z"/>
                    </svg>
                    <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M10 7a7 7 0 0 0 12 4.9v.1c0 5.523-4.477 10-10 10S2 17.523 2 12 6.477 2 12 2h.1A6.979 6.979 0 0 0 10 7zm-6 5a8 8 0 0 0 15.062 3.762A9 9 0 0 1 8.238 4.938 7.999 7.999 0 0 0 4 12z"/>
                    </svg>
                </button>
            </div>
        </div>
    </nav>

    <main class="main-content">
        <div class="container">
            <!-- <h1 class="page-title">Research</h1> -->
            <div class="research-content">
                <section class="research-section">
                    <h2>Selected Publications (* equal contribution)</h2>
                    <div class="publications-list">
                        <div class="year-section">
                            <h3>2025</h3>
                            <div class="publication-item">
                                <h4>MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models</h4>
                                <p class="venue">EMNLP 2025</p>
                                <p class="authors">Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Yayue Deng, Jing Ma</p>
                                <div class="links">
                                    <a href="" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>MM-CRITIC: A Holistic Evaluation of Large Multimodal Models as Multimodal Critique</h4>
                                <p class="venue">EMNLP 2025</p>
                                <p class="authors">Gailun Zeng, Ziyang Luo, Hongzhan Lin, Yuchen Tian, Kaixin Li, Ziyang Gong, Jianxiong Guo, Jing Ma</p>
                                <div class="links">
                                    <a href="" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Aria-UI: Visual Grounding for GUI Instructions</h4>
                                <p class="venue">ACL 2025</p>
                                <p class="authors">Yuhao Yang, Yue Wang, Dongxu Li, Ziyang Luo, Bei Chen, Chao Huang, and Junnan Li</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2412.16256" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models</h4>
                                <p class="venue">ACL 2025</p>
                                <p class="authors">Ziyang Luo, Kaixin Li, Hongzhan Lin, Yuchen Tian, Mohan Kankanhalli, and Jing Ma</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2025.acl-long.14/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Meme Harmfulness</h4>
                                <p class="venue">ACL 2025</p>
                                <p class="authors">Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Zhen Ye, Guang Chen, Zhiyong Huang, Jing Ma</p>
                                <div class="links">
                                    <a href="https://arxiv.org/pdf/2507.01702" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>SHARP: Unlocking Interactive Hallucination via Stance Transfer in Role-Playing Agents</h4>
                                <p class="venue">ACL 2025</p>
                                <p class="authors">Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi SUN, Jing Ma</p>
                                <div class="links">
                                    <a href="https://arxiv.org/pdf/2411.07965" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>VideoAutoArena: An Automated Arena for Evaluating Large Multimodal Models in Video Analysis through User Simulation</h4>
                                <p class="venue">CVPR 2025</p>
                                <p class="authors">Ziyang Luo, Haoning Wu, Dongxu Li, Jing Ma, Mohan Kankanhalli, and Junnan Li</p>
                                <div class="links">
                                    <a href="https://arxiv.org/pdf/2411.13281" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://videoautoarena.github.io/" target="_blank" rel="noopener noreferrer">Project Page</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>ScreenSpot-Pro: GUI Grounding for Professional High-Resolution Computer Use</h4>
                                <p class="venue">ACM Multimedia 2025</p>
                                <p class="venue">ICLR 2025 Workshop</p>
                                <p class="authors">Kaixin Li, Ziyang Meng, Hongzhan Lin, Ziyang Luo, Yuchen Tian, Jing Ma, Zhiyong Huang and Tat-Seng Chua</p>
                                <div class="links">
                                    <a href="https://likaixin2000.github.io/papers/ScreenSpot_Pro.pdf" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://gui-agent.github.io/grounding-leaderboard/" target="_blank" rel="noopener noreferrer">Project Page</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>ScratchEval: Are GPT-4o Smarter than My Child? Evaluating Large Multimodal Models with Visual Programming Challenges</h4>
                                <p class="venue">NAACL 2025</p>
                                <p class="authors">Rao Fu, Ziyang Luo, Hongzhan Lin, Zhen Ye, Jing Ma</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2411.18932" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://github.com/HKBUNLP/ScratchEval" target="_blank" rel="noopener noreferrer">Code</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>CodeHalu: Code Hallucinations in LLMs Driven by Execution-based Verification</h4>
                                <p class="venue">AAAI 2025</p>
                                <p class="authors">Yuchen Tian, Weixiang Yan, Qian Yang, Xuandong Zhao, Qian Chen, Wen Wang, Ziyang Luo, Lei Ma, Dawn Song</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2405.00253" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://github.com/yuchen814/CodeHalu" target="_blank" rel="noopener noreferrer">Code</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?</h4>
                                <p class="venue">COLING 2025</p>
                                <p class="authors">Yuwei Zhao*, Ziyang Luo*, Yuchen Tian, Hongzhan Lin, Weixiang Yan, Annan Li, and Jing Ma</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2408.10718" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://huggingface.co/datasets/CodeResearch/CodeJudge-Eval" target="_blank" rel="noopener noreferrer">Data</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>EXPLAINHM++: Explainable Harmful Meme Detection with Retrieval-Augmented Debate between Large Multimodal Models</h4>
                                <p class="venue">The IEEE Transactions on Knowledge and Data Engineering (TKDE)</p>
                                <p class="authors">Hongzhan Lin, Wei Gao, Jing Ma, Yang Deng, Ziyang Luo, Bo Wang, Ruichao Yang, Tat-Seng Chua</p>
                                <div class="links">
                                    <a href="" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            
                            <div class="publication-item">
                                <h4>GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse</h4>
                                <p class="venue">ACM Transactions on Intelligent Systems and Technology (TIST)</p>
                                <p class="authors">Hongzhan Lin*, Ziyang Luo*, Bo Wang, Ruichao Yang, and Jing Ma</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2401.01523" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://goatlmm.github.io/" target="_blank" rel="noopener noreferrer">Data</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns</h4>
                                <p class="venue">Transactions of the Association for Computational Linguistics (TACL)</p>
                                <p class="authors">Xin Chen, Junchao Wu, Shu Yang, Runzhe Zhan, Zeyu Wu, Ziyang Luo, Di Wang, Min Yang, Lidia S. Chao, Derek F. Wong</p>
                                <div class="links">
                                    <a href="" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>MFC-Bench: Benchmarking Multimodal Fact-Checking with Large Vision-Language Models</h4>
                                <p class="venue">ICLR 2025 Workshop</p>
                                <p class="authors">Shengkang Wang*, Hongzhan Lin*, Ziyang Luo*, Zhen Ye, Guang Chen, and Jing Ma</p>
                                <div class="links">
                                    <a href="https://arxiv.org/pdf/2406.11288" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://github.com/wskbest/MFC-Bench" target="_blank" rel="noopener noreferrer">Data</a>
                                </div>
                            </div>
                        </div>

                        <div class="year-section">
                            <h3>2024</h3>
                            <div class="publication-item">
                                <h4>WizardCoder: Empowering Code Large Language Models with Evol-Instruct</h4>
                                <p class="venue">ICLR 2024</p>
                                <p class="authors">Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2306.08568" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://huggingface.co/WizardLM/WizardCoder-15B-V1.0" target="_blank" rel="noopener noreferrer">Model</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation</h4>
                                <p class="venue">EMNLP 2024</p>
                                <p class="authors">Ziyang Luo, Xin Li, Hongzhan Lin, Jing Ma, and Lidong Bing</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2410.00558" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Towards Low-Resource Harmful Meme Detection with LMM Agents</h4>
                                <p class="venue">EMNLP 2024</p>
                                <p class="authors">Jianzhao Huang, Hongzhan Lin, Ziyan Liu, Ziyang Luo, Guang Chen, and Jing Ma</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2024.emnlp-main.136/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems</h4>
                                <p class="venue">EMNLP 2024</p>
                                <p class="authors">Kaixin Li, Yuchen Tian, Qisheng Hu, Ziyang Luo, and Jing Ma</p>
                                <div class="links">
                                    <a href="https://arxiv.org/pdf/2404.09486.pdf" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://huggingface.co/datasets/likaixin/MMCode" target="_blank" rel="noopener noreferrer">Data</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models</h4>
                                <p class="venue">ACL 2024</p>
                                <p class="authors">Zixin Chen, Hongzhan Lin, Ziyang Luo, Mingfei Cheng, Jing Ma, and Guang Chen</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2405.00390" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://github.com/Lbotirx/CofiPara" target="_blank" rel="noopener noreferrer">Code</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models</h4>
                                <p class="venue">WWW 2024</p>
                                <p class="authors">Hongzhan Lin, Ziyang Luo, Wei Gao, Jing Ma, Bo Wang, and Ruichao Yang</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2401.13298" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://github.com/HKBUNLP/ExplainHM-WWW2024" target="_blank" rel="noopener noreferrer">Code</a>
                                </div>
                            </div>
                        </div>

                        <div class="year-section">
                            <h3>2023</h3>
                            <div class="publication-item">
                                <h4>LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale Image-Text Sparse Retrieval</h4>
                                <p class="venue">ICCV 2023</p>
                                <p class="authors">Ziyang Luo, Pu Zhao, Can Xu, Xiubo Geng, Tao Shen, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang</p>
                                <div class="links">
                                    <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.pdf" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://github.com/ChiYeungLaw/LexLIP-ICCV23" target="_blank" rel="noopener noreferrer">Code</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models</h4>
                                <p class="venue">EMNLP 2023</p>
                                <p class="authors">Hongzhan Lin*, Ziyang Luo*, Jing Ma, and Long Chen</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2023.findings-emnlp.611/" target="_blank" rel="noopener noreferrer">Paper</a>
                                    <a href="https://github.com/HKBUNLP/Mr.Harm-EMNLP2023" target="_blank" rel="noopener noreferrer">Code</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning</h4>
                                <p class="venue">AAAI 2023</p>
                                <p class="authors">Hongzhan Lin, Pengyao Yi, Jing Ma, Haiyun Jiang, Ziyang Luo, Shuming Shi, Ruifang Liu</p>
                                <div class="links">
                                    <a href="https://arxiv.org/abs/2212.01117" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>
                        </div>

                        <div class="year-section">
                            <h3>2022</h3>
                            <div class="publication-item">
                                <h4>A Coarse-to-fine Cascaded Evidence-Distillation Neural Network for Explainable Fake News Detection</h4>
                                <p class="venue">COLING 2022</p>
                                <p class="authors">Zhiwei Yang, Jing Ma, Hechang Chen, Hongzhan Lin, Ziyang Luo, Yi Chang</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2022.coling-1.230/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Conditioned Masked Language and Image Modeling for Image-Text Dense Retrieval</h4>
                                <p class="venue">EMNLP 2022</p>
                                <p class="authors">Ziyang Luo, Yadong Xi, Rongsheng Zhang, Gongzheng Li, Zeng Zhao, and Jing Ma</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2022.findings-emnlp.10/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>DecBERT: Enhancing the Language Understanding of BERT with Causal Attention Masks</h4>
                                <p class="venue">NAACL 2022</p>
                                <p class="authors">Ziyang Luo, Yadong Xi, Jing Ma, Zhiwei Yang, Xiaoxi Mao, Changjie Fan, Rongsheng Zhang</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2022.findings-naacl.89/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Easy and Efficient Transformer: Scalable Inference Solution for Large NLP Model</h4>
                                <p class="venue">NAACL 2022</p>
                                <p class="authors">Yadong Xi, Gongzheng Li, Jingzhen Ding, Duan Wang, Ziyang Luo, Rongsheng Zhang, Bai Liu, Changjie Fan, Xiaoxi Mao, Zeng Zhao</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2022.naacl-industry.8/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>
                        </div>

                        <div class="year-section">
                            <h3>2021</h3>
                            <div class="publication-item">
                                <h4>Positional Artefacts Propagate Through Masked Language Model Embeddings</h4>
                                <p class="venue">ACL 2021</p>
                                <p class="authors">Ziyang Luo, Artur Kulmizev, and Xiaoxi Mao</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2021.acl-long.413/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Smoothing with Fake Label</h4>
                                <p class="venue">CIKM 2021</p>
                                <p class="authors">Ziyang Luo, Yadong Xi, and Xiaoxi Mao</p>
                                <div class="links">
                                    <a href="/research/Fake_Label_CIKM.pdf" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese Adjectives</h4>
                                <p class="venue">GeBNLP 2021</p>
                                <p class="authors">Meichun Jiao, Ziyang Luo</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2021.gebnlp-1.2/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>

                            <div class="publication-item">
                                <h4>Have Attention Heads in BERT Learned Constituency Grammar?</h4>
                                <p class="venue">EACL 2021 SRW</p>
                                <p class="authors">Ziyang Luo</p>
                                <div class="links">
                                    <a href="https://aclanthology.org/2021.eacl-srw.2/" target="_blank" rel="noopener noreferrer">Paper</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <section class="research-section">
                    <h2>Selected Open-Source Projects</h2>
                    <div class="publications-list">
                        <div class="publication-item">
                            <h4>VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs</h4>
                            <p class="authors">VideoLLaMA Team@Alibaba</p>
                            <div class="links">
                                <a href="https://arxiv.org/pdf/2406.07476" target="_blank" rel="noopener noreferrer">Paper</a>
                                <a href="https://github.com/DAMO-NLP-SG/VideoLLaMA2" target="_blank" rel="noopener noreferrer">Code</a>
                            </div>
                        </div>

                        <div class="publication-item">
                            <h4>WizardCoder: Empowering Code Large Language Models with Evol-Instruct</h4>
                            <p class="authors">WizardLM Team@Microsoft</p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2306.08568" target="_blank" rel="noopener noreferrer">Paper</a>
                                <a href="https://github.com/nlpxucan/WizardLM" target="_blank" rel="noopener noreferrer">Code</a>
                            </div>
                        </div>

                        <div class="publication-item">
                            <h4>AURORA-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order</h4>
                            <p class="authors">Aurora-M Open-Source Community</p>
                            <div class="links">
                                <a href="https://arxiv.org/pdf/2404.00399.pdf" target="_blank" rel="noopener noreferrer">Paper</a>
                                <a href="https://huggingface.co/collections/aurora-m/aurora-m-models-65fdfdff62471e09812f5407" target="_blank" rel="noopener noreferrer">Models</a>
                            </div>
                        </div>
                    </div>
                </section>

                <section class="research-section">
                    <h2>Master Thesis</h2>
                    <div class="publications-list">
                        <div class="publication-item">
                            <h4>Analyzing the Anisotropy Phenomenon in Transformer-based Masked Language Models</h4>
                            <p class="authors">Supervised by <a href="https://scholar.google.nl/citations?hl=en&user=Cgg6_W0AAAAJ&view_op=list_works&sortby=pubdate" target="_blank" rel="noopener noreferrer">Artur Kulmizev</a>, Uppsala University, 2021</p>
                            <div class="links">
                                <a href="http://uu.diva-portal.org/smash/record.jsf?pid=diva2%3A1565827&dswid=61" target="_blank" rel="noopener noreferrer">Thesis</a>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </div>
    </main>
    <script>
        // Theme toggle functionality
        const themeToggle = document.getElementById('theme-toggle');
        const html = document.documentElement;
        
        // Check for saved theme preference or default to system preference
        const getPreferredTheme = () => {
            const savedTheme = localStorage.getItem('theme');
            if (savedTheme) {
                return savedTheme;
            }
            return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
        };
        
        // Apply theme
        const setTheme = (theme) => {
            html.setAttribute('data-theme', theme);
            localStorage.setItem('theme', theme);
        };
        
        // Initialize theme
        setTheme(getPreferredTheme());
        
        // Toggle theme on button click
        themeToggle.addEventListener('click', () => {
            const currentTheme = html.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            setTheme(newTheme);
        });
    </script>
</body>
</html>